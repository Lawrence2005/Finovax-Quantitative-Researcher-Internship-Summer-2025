{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f9bb7c",
   "metadata": {},
   "source": [
    "## üé≠ NLP Market Sentiment Analysis Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed622a",
   "metadata": {},
   "source": [
    "### ‚Çø Crypto Fear & Greed Index Fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec372e",
   "metadata": {},
   "source": [
    "Import of Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3745789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f21dad",
   "metadata": {},
   "source": [
    "Function for Fetching Daily Crypto Fear & Greed Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2a7af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FNG_index(limit=60, format='json', date_format='cn'):\n",
    "    \"\"\"\n",
    "    Fetch the daily Fear and Greed Index data from the Alternative.me API.\n",
    "\n",
    "    Parameters:\n",
    "    limit (int): The number of entries to return (Default to 60, which returns the latest 60 days of data; set to 0 for all available data).\n",
    "    format (str): The format of the response (Default to 'json').\n",
    "    date_format (str): The format of the date in the response (Default to 'cn' for Chinese format).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A date-indexed DataFrame containing the Fear and Greed Index values and their classifications.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If the API request fails or returns an error status code.\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://api.alternative.me/fng/\"\n",
    "    params = {\n",
    "        \"limit\": limit,\n",
    "        \"format\": format,\n",
    "        \"date_format\": date_format\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        indices = pd.DataFrame(data['data'])\n",
    "        indices = indices.sort_values('timestamp', ascending=True).reset_index(drop=True).set_index('timestamp')\n",
    "        indices = indices[['value', 'value_classification']]\n",
    "\n",
    "        return indices\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782065cc",
   "metadata": {},
   "source": [
    "Fear & Greed Index of the Past Two Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0cd0e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "fng_index = get_FNG_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19cd3097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value_classification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-05-19</th>\n",
       "      <td>74</td>\n",
       "      <td>Greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-20</th>\n",
       "      <td>71</td>\n",
       "      <td>Greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-21</th>\n",
       "      <td>70</td>\n",
       "      <td>Greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-22</th>\n",
       "      <td>72</td>\n",
       "      <td>Greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-23</th>\n",
       "      <td>78</td>\n",
       "      <td>Extreme Greed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value value_classification\n",
       "timestamp                            \n",
       "2025-05-19    74                Greed\n",
       "2025-05-20    71                Greed\n",
       "2025-05-21    70                Greed\n",
       "2025-05-22    72                Greed\n",
       "2025-05-23    78        Extreme Greed"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fng_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9843c855",
   "metadata": {},
   "source": [
    "### üåê FinBERT Financial Market Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064428e1",
   "metadata": {},
   "source": [
    "Import of Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e822a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df7e97",
   "metadata": {},
   "source": [
    "Functions for Loading the FinBERT Model and Predicting text(s) using FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62eb3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FINBERT_model_create():\n",
    "    \"\"\"\n",
    "    Create and return the FINBERT model and tokenizer.\n",
    "\n",
    "    Returns:\n",
    "    tokenizer (AutoTokenizer): The tokenizer for the FINBERT model.\n",
    "    model (AutoModelForSequenceClassification): The FINBERT model for sequence classification.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the tokenizer and model from the pre-trained FINBERT model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb401414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FINBERT_predict(tokenizer, model, texts: list[str] | str):\n",
    "    \"\"\"\n",
    "    Predict sentiment using the FINBERT model.\n",
    "\n",
    "    Parameters:\n",
    "    tokenizer: The tokenizer for the FINBERT model.\n",
    "    model: The FINBERT model.\n",
    "    text (list[str] | str): The input text(s) to analyze.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted sentiment label.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    predictions = {}\n",
    "    tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "    \n",
    "    for t in texts:\n",
    "        with torch.no_grad():\n",
    "            input_sequence = tokenizer(t, return_tensors=\"pt\", **tokenizer_kwargs)\n",
    "            logits = model(**input_sequence).logits\n",
    "            scores = {\n",
    "                k: v\n",
    "                for k, v in zip(\n",
    "                    model.config.id2label.values(),\n",
    "                    scipy.special.softmax(logits.numpy().squeeze()),\n",
    "                )\n",
    "            }\n",
    "        sentimentFinbert = max(scores, key=scores.get)\n",
    "        sentiment_prob = round(float(max(scores.values())), 2)\n",
    "\n",
    "        predictions[t] = (sentimentFinbert, sentiment_prob)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f60957",
   "metadata": {},
   "source": [
    "Financial PhraseBank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42cca296",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = pd.read_csv('sentiment-data-kaggle.csv', # Replace with any CSV file containing sentiment data\n",
    "                   encoding='unicode_escape',\n",
    "                   names=['Sentiment', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74f0c71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905d386",
   "metadata": {},
   "source": [
    "Sentiment Analysis of Financial PhraseBank Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e85d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FINBERT model and tokenizer\n",
    "tokenizer, model = FINBERT_model_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d30e9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts for prediction\n",
    "texts = sentiment_data['Text'].tolist()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be4e028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = FINBERT_predict(tokenizer, model, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dddb5726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .': ('neutral',\n",
       "  0.89),\n",
       " 'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .': ('neutral',\n",
       "  0.53),\n",
       " 'The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .': ('negative',\n",
       "  0.97),\n",
       " 'With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .': ('positive',\n",
       "  0.95)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
